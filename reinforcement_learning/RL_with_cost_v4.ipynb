{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "iGiCJbnj3lN3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iGiCJbnj3lN3",
    "outputId": "7d811fcc-0226-454e-ede6-508c6048ded0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: mplfinance in /usr/local/lib/python3.7/dist-packages (0.12.9b1)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from mplfinance) (3.2.2)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from mplfinance) (1.3.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mplfinance) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mplfinance) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mplfinance) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mplfinance) (1.21.6)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mplfinance) (3.0.9)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->mplfinance) (4.1.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->mplfinance) (1.15.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->mplfinance) (2022.2.1)\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.7/dist-packages (2.5.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (1.21.6)\n",
      "Requirement already satisfied: protobuf<=3.20.1,>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (3.17.3)\n",
      "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf<=3.20.1,>=3.8.0->tensorboardX) (1.15.0)\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "!pip install mplfinance\n",
    "!pip install tensorboardX\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e540f844-9675-4aed-a5a6-6c0093528de9",
   "metadata": {
    "id": "e540f844-9675-4aed-a5a6-6c0093528de9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.experimental.output_all_intermediates(True)\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, LSTM\n",
    "from tensorflow.keras import backend as K\n",
    "#tf.config.experimental_run_functions_eagerly(True) # used for debuging and development\n",
    "tf.compat.v1.disable_eager_execution() # usually using this for fastest performance\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if len(gpus) > 0:\n",
    "    print(f'GPUs {gpus}')\n",
    "    try: tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    except RuntimeError: pass\n",
    "\n",
    "class Actor_Model:\n",
    "    def __init__(self, input_shape, action_space, lr, optimizer):\n",
    "        X_input = Input(input_shape)\n",
    "        self.action_space = action_space\n",
    "\n",
    "        #X = Flatten(input_shape=input_shape)(X_input)\n",
    "        #X = LSTM(32,return_sequences = False ,input_shape=input_shape, activation='tanh')(X_input)\n",
    "        X = LSTM(100, recurrent_activation = 'sigmoid', recurrent_dropout=0, unroll=True)(X_input)\n",
    "        #X = Dense(512, activation=\"relu\")(X)\n",
    "        #X = Dense(256, activation=\"relu\")(X)\n",
    "        #X = Dense(128, activation=\"relu\")(X)\n",
    "        X = Dense(64, activation=\"relu\")(X)\n",
    "        output = Dense(self.action_space, activation=\"softmax\")(X)\n",
    "\n",
    "        self.Actor = Model(inputs = X_input, outputs = output)\n",
    "        self.Actor.compile(loss=self.ppo_loss, optimizer=optimizer(learning_rate=lr))\n",
    "\n",
    "    def ppo_loss(self, y_true, y_pred):\n",
    "        # Defined in https://arxiv.org/abs/1707.06347\n",
    "        advantages, prediction_picks, actions = y_true[:, :1], y_true[:, 1:1+self.action_space], y_true[:, 1+self.action_space:]\n",
    "        LOSS_CLIPPING = 0.2\n",
    "        ENTROPY_LOSS = 0.001\n",
    "        \n",
    "        prob = actions * y_pred\n",
    "        old_prob = actions * prediction_picks\n",
    "\n",
    "        prob = K.clip(prob, 1e-10, 1.0)\n",
    "        old_prob = K.clip(old_prob, 1e-10, 1.0)\n",
    "\n",
    "        ratio = K.exp(K.log(prob) - K.log(old_prob))\n",
    "        \n",
    "        p1 = ratio * advantages\n",
    "        p2 = K.clip(ratio, min_value=1 - LOSS_CLIPPING, max_value=1 + LOSS_CLIPPING) * advantages\n",
    "\n",
    "        actor_loss = -K.mean(K.minimum(p1, p2))\n",
    "\n",
    "        entropy = -(y_pred * K.log(y_pred + 1e-10))\n",
    "        entropy = ENTROPY_LOSS * K.mean(entropy)\n",
    "        \n",
    "        total_loss = actor_loss - entropy\n",
    "\n",
    "        return total_loss\n",
    "\n",
    "    def predict(self, state):\n",
    "        return self.Actor.predict(state)\n",
    "\n",
    "class Critic_Model:\n",
    "    def __init__(self, input_shape, action_space, lr, optimizer):\n",
    "        X_input = Input(input_shape)\n",
    "\n",
    "        #V = Flatten(input_shape=input_shape)(X_input)\n",
    "        #V = LSTM(32,return_sequences = False,input_shape=input_shape, activation='tanh')(X_input)\n",
    "        V = LSTM(100, recurrent_activation = 'sigmoid', recurrent_dropout=0, unroll=True)(X_input)\n",
    "        #V = Dense(512, activation=\"relu\")(V)\n",
    "        #V = Dense(256, activation=\"relu\")(V)\n",
    "        #V = Dense(128, activation=\"relu\")(V)\n",
    "        V = Dense(64, activation=\"relu\")(V)\n",
    "        value = Dense(1, activation=None)(V)\n",
    "\n",
    "        self.Critic = Model(inputs=X_input, outputs = value)\n",
    "        self.Critic.compile(loss=self.critic_PPO2_loss, optimizer=optimizer(learning_rate=lr))\n",
    "\n",
    "    def critic_PPO2_loss(self, y_true, y_pred):\n",
    "        value_loss = K.mean((y_true - y_pred) ** 2) # standard PPO loss\n",
    "        return value_loss\n",
    "\n",
    "    def predict(self, state):\n",
    "        return self.Critic.predict([state, np.zeros((state.shape[0], 1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "404e6882-68f1-47cd-aef1-0a5221903cad",
   "metadata": {
    "id": "404e6882-68f1-47cd-aef1-0a5221903cad"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "from mplfinance.original_flavor import candlestick_ohlc\n",
    "import matplotlib.dates as mpl_dates\n",
    "from datetime import datetime, date\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def Write_to_file(Date, net_worth, filename='{}.txt'.format(datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))):\n",
    "    for i in net_worth: \n",
    "        Date += \" {}\".format(i)\n",
    "    #print(Date)\n",
    "    if not os.path.exists('logs'):\n",
    "        os.makedirs('logs')\n",
    "    file = open(\"logs/\"+filename, 'a+')\n",
    "    file.write(Date+\"\\n\")\n",
    "    file.close()\n",
    "\n",
    "class TradingGraph:\n",
    "    # A crypto trading visualization using matplotlib made to render custom prices which come in following way:\n",
    "    # Date, Open, High, Low, Close, Volume, net_worth, trades\n",
    "    # call render every step\n",
    "    def __init__(self, Render_range):\n",
    "        self.Volume = deque(maxlen=Render_range)\n",
    "        self.net_worth = deque(maxlen=Render_range)\n",
    "        self.render_data = deque(maxlen=Render_range)\n",
    "        self.Render_range = Render_range\n",
    "\n",
    "        # We are using the style ‘ggplot’\n",
    "        plt.style.use('ggplot')\n",
    "        # close all plots if there are open\n",
    "        plt.close('all')\n",
    "        # figsize attribute allows us to specify the width and height of a figure in unit inches\n",
    "        self.fig = plt.figure(figsize=(16,8)) \n",
    "\n",
    "        # Create top subplot for price axis\n",
    "        self.ax1 = plt.subplot2grid((6,1), (0,0), rowspan=5, colspan=1)\n",
    "        \n",
    "        # Create bottom subplot for volume which shares its x-axis\n",
    "        self.ax2 = plt.subplot2grid((6,1), (5,0), rowspan=1, colspan=1, sharex=self.ax1)\n",
    "        \n",
    "        # Create a new axis for net worth which shares its x-axis with price\n",
    "        self.ax3 = self.ax1.twinx()\n",
    "\n",
    "        # Formatting Date\n",
    "        self.date_format = mpl_dates.DateFormatter('%d-%m-%Y')\n",
    "        #self.date_format = mpl_dates.DateFormatter('%d-%m-%Y')\n",
    "        \n",
    "        # Add paddings to make graph easier to view\n",
    "        #plt.subplots_adjust(left=0.07, bottom=-0.1, right=0.93, top=0.97, wspace=0, hspace=0)\n",
    "\n",
    "    # Render the environment to the screen\n",
    "    def render(self, Date, Open, High, Low, Close, Volume, net_worth, trades):\n",
    "        # append volume and net_worth to deque list\n",
    "        self.Volume.append(Volume)\n",
    "        self.net_worth.append(net_worth)\n",
    "\n",
    "        # before appending to deque list, need to convert Date to special format\n",
    "        Date = mpl_dates.date2num([pd.to_datetime(Date)])[0]\n",
    "        self.render_data.append([Date, Open, High, Low, Close])\n",
    "        \n",
    "        # Clear the frame rendered last step\n",
    "        self.ax1.clear()\n",
    "        candlestick_ohlc(self.ax1, self.render_data, width=8/24, colorup='green', colordown='red', alpha=0.8)\n",
    "\n",
    "        # Put all dates to one list and fill ax2 sublot with volume\n",
    "        Date_Render_range = [i[0] for i in self.render_data]\n",
    "        self.ax2.clear()\n",
    "        self.ax2.fill_between(Date_Render_range, self.Volume, 0)\n",
    "\n",
    "        # draw our net_worth graph on ax3 (shared with ax1) subplot\n",
    "        self.ax3.clear()\n",
    "        self.ax3.plot(Date_Render_range, self.net_worth, color=\"blue\")\n",
    "        \n",
    "        # beautify the x-labels (Our Date format)\n",
    "        self.ax1.xaxis.set_major_formatter(self.date_format)\n",
    "        self.fig.autofmt_xdate()\n",
    "\n",
    "        # sort sell and buy orders, put arrows in appropiate order positions\n",
    "        for trade in trades:\n",
    "            trade_date = mpl_dates.date2num([pd.to_datetime(trade['Date'])])[0]\n",
    "            if trade_date in Date_Render_range:\n",
    "                if trade['type'] == 'buy':\n",
    "                    high_low = trade['Low']-10\n",
    "                    self.ax1.scatter(trade_date, high_low, c='green', label='green', s = 120, edgecolors='none', marker=\"^\")\n",
    "                else:\n",
    "                    high_low = trade['High']+10\n",
    "                    self.ax1.scatter(trade_date, high_low, c='red', label='red', s = 120, edgecolors='none', marker=\"v\")\n",
    "\n",
    "        # we need to set layers every step, because we are clearing subplots every step\n",
    "        self.ax2.set_xlabel('Date')\n",
    "        self.ax1.set_ylabel('Price')\n",
    "        self.ax3.set_ylabel('Balance')\n",
    "\n",
    "        # I use tight_layout to replace plt.subplots_adjust\n",
    "        self.fig.tight_layout()\n",
    "\n",
    "        \"\"\"Display image with matplotlib - interrupting other tasks\"\"\"\n",
    "        # Show the graph without blocking the rest of the program\n",
    "        plt.show(block=False)\n",
    "        # Necessary to view frames before they are unrendered\n",
    "        plt.pause(0.001)\n",
    "\n",
    "        \"\"\"Display image with OpenCV - no interruption\"\"\"\n",
    "        #####redraw the canvas\n",
    "        self.fig.canvas.draw()\n",
    "        ######convert canvas to image\n",
    "        img = np.fromstring(self.fig.canvas.tostring_rgb(), dtype=np.uint8, sep='')\n",
    "        img  = img.reshape(self.fig.canvas.get_width_height()[::-1] + (3,))\n",
    "\n",
    "        ########img is rgb, convert to opencv's default bgr\n",
    "        image = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        #########display image with OpenCV or any operation you like\n",
    "        #################################\n",
    "        cv2.imshow(\"Bitcoin trading bot\",image)\n",
    "\n",
    "        if cv2.waitKey(25) & 0xFF == ord(\"q\"):\n",
    "            cv2.destroyAllWindows()\n",
    "            return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd4ae416-8e2d-41e1-ba1b-e42ec9ea6b7f",
   "metadata": {
    "id": "bd4ae416-8e2d-41e1-ba1b-e42ec9ea6b7f"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "import copy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import deque\n",
    "from tensorboardX import SummaryWriter\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "\n",
    "class CustomEnv:\n",
    "    # A custom Bitcoin trading environment\n",
    "    def __init__(self, df, initial_balance=1000, lookback_window_size=50, Render_range = 100):\n",
    "        # Define action space and state size and other custom parameters\n",
    "        self.df = df.dropna().reset_index()\n",
    "        self.df_total_steps = len(self.df)-1\n",
    "        self.initial_balance = initial_balance\n",
    "        self.lookback_window_size = lookback_window_size\n",
    "        self.Render_range = Render_range # render range in visualization\n",
    "\n",
    "        # Action space from 0 to 3, 0 is hold, 1 is buy, 2 is sell\n",
    "        self.action_space = np.array([0, 1])\n",
    "\n",
    "        # Orders history contains the balance, net_worth, crypto_bought, crypto_sold, crypto_held values for the last lookback_window_size steps\n",
    "        self.orders_history = deque(maxlen=self.lookback_window_size)\n",
    "        \n",
    "        # Market history contains the OHCL values for the last lookback_window_size prices\n",
    "        self.market_history = deque(maxlen=self.lookback_window_size)\n",
    "\n",
    "        # State size contains Market+Orders history for the last lookback_window_size steps\n",
    "        self.state_size = (self.lookback_window_size, 18)\n",
    "\n",
    "        # Neural Networks part bellow\n",
    "        self.lr = 0.00001\n",
    "        self.epochs = 1\n",
    "        self.normalize_value = 100000\n",
    "        self.optimizer = Adam\n",
    "\n",
    "        # Create Actor-Critic network model\n",
    "        self.Actor = Actor_Model(input_shape=self.state_size, action_space = self.action_space.shape[0], lr=self.lr, optimizer = self.optimizer)\n",
    "        self.Critic = Critic_Model(input_shape=self.state_size, action_space = self.action_space.shape[0], lr=self.lr, optimizer = self.optimizer)\n",
    "\n",
    "    # create tensorboard writer\n",
    "    def create_writer(self):\n",
    "        self.replay_count = 0\n",
    "        self.writer = SummaryWriter(comment=\"Crypto_trader\")\n",
    "\n",
    "    # Reset the state of the environment to an initial state\n",
    "    def reset(self, env_steps_size = 0):\n",
    "        self.visualization = TradingGraph(Render_range=self.Render_range) # init visualization\n",
    "        self.trades = deque(maxlen=self.Render_range) # limited orders memory for visualization\n",
    "        \n",
    "        self.balance = self.initial_balance\n",
    "        self.net_worth = self.initial_balance\n",
    "        self.prev_net_worth = self.initial_balance\n",
    "        self.crypto_held = 0\n",
    "        self.crypto_sold = 0\n",
    "        self.crypto_bought = 0\n",
    "        self.episode_orders = 0 # test\n",
    "        self.env_steps_size = env_steps_size\n",
    "        if env_steps_size > 0: # used for training dataset\n",
    "            self.start_step = random.randint(self.lookback_window_size, self.df_total_steps - env_steps_size)\n",
    "            self.end_step = self.start_step + env_steps_size\n",
    "        else: # used for testing dataset\n",
    "            self.start_step = self.lookback_window_size\n",
    "            self.end_step = self.df_total_steps\n",
    "            \n",
    "        self.current_step = self.start_step\n",
    "\n",
    "        for i in reversed(range(self.lookback_window_size)):\n",
    "            current_step = self.current_step - i\n",
    "            self.orders_history.append([self.balance, self.net_worth, self.crypto_bought, self.crypto_sold, self.crypto_held])\n",
    "            self.market_history.append([#self.df.loc[current_step, 'Open'],\n",
    "                                        #self.df.loc[current_step, 'High'],\n",
    "                                        #self.df.loc[current_step, 'Low'],\n",
    "                                        self.df.loc[current_step, 'Close'],\n",
    "                                        #self.df.loc[current_step, 'Volume']\n",
    "                                        self.df.loc[current_step, 'Volume'],#\n",
    "                                        #self.df.loc[current_step, 'asset_volume'],#\n",
    "                                        self.df.loc[current_step, 'num_trades'],#\n",
    "                                        #self.df.loc[current_step, 'taker_base_volume'],#\n",
    "                                        #self.df.loc[current_step, 'taker_quote_volume'],#\n",
    "                                        self.df.loc[current_step, 'SMA_20'],#\n",
    "                                        self.df.loc[current_step, 'SMA_60'],#\n",
    "                                        self.df.loc[current_step, 'RSI'],#\n",
    "                                        self.df.loc[current_step, 'Bollinger_up_20'],\n",
    "                                        self.df.loc[current_step, 'Bollinger_down_20'],\n",
    "                                        self.df.loc[current_step, 'DIF'],\n",
    "                                        self.df.loc[current_step, 'DEA'],\n",
    "                                        self.df.loc[current_step, 'MACD'],\n",
    "                                        self.df.loc[current_step, 'OBV'],\n",
    "                                        self.df.loc[current_step, 'ATR'],\n",
    "                                        #self.df.loc[current_step, 'Positive_sentiment']                                       \t\t\t\t\t\t\n",
    "                                        ])\n",
    "\n",
    "        state = np.concatenate((self.market_history, self.orders_history), axis=1)\n",
    "        return state\n",
    "\n",
    "    # Get the data points for the given current_step\n",
    "    def _next_observation(self):\n",
    "        self.market_history.append([#self.df.loc[self.current_step, 'Open'],\n",
    "                                    #self.df.loc[self.current_step, 'High'],\n",
    "                                    #self.df.loc[self.current_step, 'Low'],\n",
    "                                    self.df.loc[self.current_step, 'Close'],\n",
    "                                    #self.df.loc[self.current_step, 'Volume']\n",
    "                                    self.df.loc[self.current_step, 'Volume'],#\n",
    "                                    #self.df.loc[self.current_step, 'asset_volume'],#\n",
    "                                    self.df.loc[self.current_step, 'num_trades'],#\n",
    "                                    #self.df.loc[self.current_step, 'taker_base_volume'],#\n",
    "                                    #self.df.loc[self.current_step, 'taker_quote_volume'],#\n",
    "                                    self.df.loc[self.current_step, 'SMA_20'],#\n",
    "                                    self.df.loc[self.current_step, 'SMA_60'],#\n",
    "                                    self.df.loc[self.current_step, 'RSI'],#\n",
    "                                    self.df.loc[self.current_step, 'Bollinger_up_20'],#\n",
    "                                    self.df.loc[self.current_step, 'Bollinger_down_20'],#\n",
    "                                    self.df.loc[self.current_step, 'DIF'],#\n",
    "                                    self.df.loc[self.current_step, 'DEA'],#\n",
    "                                    self.df.loc[self.current_step, 'MACD'],#\n",
    "                                    self.df.loc[self.current_step, 'OBV'],#\n",
    "                                    self.df.loc[self.current_step, 'ATR'],\n",
    "                                    #self.df.loc[self.current_step, 'Positive_sentiment']\n",
    "                                    ])\n",
    "        #print(pd.DataFrame(self.market_history).shape)\n",
    "        #print(pd.DataFrame(self.orders_history).shape)\n",
    "\n",
    "        obs = np.concatenate((self.market_history, self.orders_history), axis=1)\n",
    "        return obs\n",
    "\n",
    "    # Execute one time step within the environment\n",
    "    def step(self, action):\n",
    "        self.crypto_bought = 0\n",
    "        self.crypto_sold = 0\n",
    "        self.current_step += 1\n",
    "\n",
    "        # Set the current price to a random price between open and close\n",
    "        current_price = random.uniform(\n",
    "            self.df.loc[self.current_step, 'Open'],\n",
    "            self.df.loc[self.current_step, 'Close'])\n",
    "        Date = self.df.loc[self.current_step, 'Date'] # for visualization\n",
    "        High = self.df.loc[self.current_step, 'High'] # for visualization\n",
    "        Low = self.df.loc[self.current_step, 'Low'] # for visualization\n",
    "        \n",
    "        #if action == 0: # Hold\n",
    "        #    pass\n",
    "\n",
    "        if action == 0 and self.balance > self.initial_balance/100: #and p > 0.5:\n",
    "            # Buy with 100% of current balance\n",
    "            self.crypto_bought = self.balance / (current_price * 1.0005)\n",
    "            self.balance -= self.crypto_bought * current_price * 1.0005\n",
    "            self.crypto_held += self.crypto_bought\n",
    "            self.trades.append({'Date' : Date, 'High' : High, 'Low' : Low, 'total': self.crypto_bought, 'type': \"buy\"})\n",
    "            self.episode_orders += 1\n",
    "\n",
    "        elif action == 1 and self.crypto_held>0:\n",
    "            # Sell 100% of current crypto held\n",
    "            self.crypto_sold = self.crypto_held\n",
    "            self.balance += (self.crypto_sold * current_price * 0.9995)\n",
    "            self.crypto_held -= self.crypto_sold\n",
    "            self.trades.append({'Date' : Date, 'High' : High, 'Low' : Low, 'total': self.crypto_sold, 'type': \"sell\"})\n",
    "            self.episode_orders += 1\n",
    "\n",
    "        self.prev_net_worth = self.net_worth\n",
    "        self.net_worth = self.balance + self.crypto_held * current_price\n",
    "\n",
    "        self.orders_history.append([self.balance, self.net_worth, self.crypto_bought, self.crypto_sold, self.crypto_held])\n",
    "        #Write_to_file(Date, self.orders_history[-1])\n",
    "\n",
    "        # Calculate reward\n",
    "        reward = self.net_worth - self.prev_net_worth\n",
    "\n",
    "        if self.net_worth <= self.initial_balance/2:\n",
    "            done = True\n",
    "        else:\n",
    "            done = False\n",
    "\n",
    "        obs = self._next_observation() #/ self.normalize_value\n",
    "        \n",
    "        return obs, reward, done\n",
    "\n",
    "    # render environment\n",
    "    def render(self, visualize = False):\n",
    "        #print(f'Step: {self.current_step}, Net Worth: {self.net_worth}')\n",
    "        if visualize:\n",
    "            Date = self.df.loc[self.current_step, 'Date']\n",
    "            Open = self.df.loc[self.current_step, 'Open']\n",
    "            Close = self.df.loc[self.current_step, 'Close']\n",
    "            High = self.df.loc[self.current_step, 'High']\n",
    "            Low = self.df.loc[self.current_step, 'Low']\n",
    "            Volume = self.df.loc[self.current_step, 'Volume']\n",
    "\n",
    "            # Render the environment to the screen\n",
    "            self.visualization.render(Date, Open, High, Low, Close, Volume, self.net_worth, self.trades)\n",
    "\n",
    "    def get_gaes(self, rewards, dones, values, next_values, gamma = 0.99, lamda = 0.95, normalize=True):\n",
    "        deltas = [r + gamma * (1 - d) * nv - v for r, d, nv, v in zip(rewards, dones, next_values, values)]\n",
    "        deltas = np.stack(deltas)\n",
    "        gaes = copy.deepcopy(deltas)\n",
    "        for t in reversed(range(len(deltas) - 1)):\n",
    "            gaes[t] = gaes[t] + (1 - dones[t]) * gamma * lamda * gaes[t + 1]\n",
    "\n",
    "        target = gaes + values\n",
    "        if normalize:\n",
    "            gaes = (gaes - gaes.mean()) / (gaes.std() + 1e-8)\n",
    "        return np.vstack(gaes), np.vstack(target)\n",
    "\n",
    "    def replay(self, states, actions, rewards, predictions, dones, next_states):\n",
    "        # reshape memory to appropriate shape for training\n",
    "        states = np.vstack(states)\n",
    "        next_states = np.vstack(next_states)\n",
    "        actions = np.vstack(actions)\n",
    "        predictions = np.vstack(predictions)\n",
    "        # Compute discounted rewards\n",
    "        #discounted_r = np.vstack(self.discount_rewards(rewards))\n",
    "\n",
    "        # Get Critic network predictions \n",
    "        values = self.Critic.predict(states)\n",
    "        next_values = self.Critic.predict(next_states)\n",
    "        # Compute advantages\n",
    "        #advantages = discounted_r - values\n",
    "        advantages, target = self.get_gaes(rewards, dones, np.squeeze(values), np.squeeze(next_values))\n",
    "        '''\n",
    "        pylab.plot(target,'-')\n",
    "        pylab.plot(advantages,'.')\n",
    "        ax=pylab.gca()\n",
    "        ax.grid(True)\n",
    "        pylab.show()\n",
    "        '''\n",
    "        # stack everything to numpy array\n",
    "        y_true = np.hstack([advantages, predictions, actions])\n",
    "        # training Actor and Critic networks\n",
    "        a_loss = self.Actor.Actor.fit(states, y_true, epochs=self.epochs, verbose=0, shuffle=True)\n",
    "        c_loss = self.Critic.Critic.fit(states, target, epochs=self.epochs, verbose=0, shuffle=True)\n",
    "\n",
    "        self.writer.add_scalar('Data/actor_loss_per_replay', np.sum(a_loss.history['loss']), self.replay_count)\n",
    "        self.writer.add_scalar('Data/critic_loss_per_replay', np.sum(c_loss.history['loss']), self.replay_count)\n",
    "        self.replay_count += 1\n",
    "        \n",
    "\n",
    "    def normalize_state(self, state):\n",
    "        #market_obs = state[:,0:1]#\n",
    "        vol_obs = state[:,1:2]#\n",
    "        no_trade = state[:,2:3]#\n",
    "\n",
    "        balance_obs = state[:,13:14]\n",
    "        networth_obs = state[:,14:15]\n",
    "        portfolio_obs = state[:,15:]\n",
    "        \n",
    "        close_prices = state[:,3:4].mean()\n",
    "        \n",
    "        \n",
    "        market_obs_nml = (state[:,0:1] - state[:,0:1].mean())/state[:,0:1].std()\n",
    "        #vol_obs_nml = tf.keras.layers.LayerNormalization(axis = 0)(vol_obs).numpy()\n",
    "        vol_obs_nml = (vol_obs - vol_obs.mean())/vol_obs.std()\n",
    "        no_trade_nml = (no_trade - no_trade.mean())/no_trade.std()\n",
    "        i_1 = (state[:,3:4] - state[:,3:4].mean())/state[:,3:4].std()\n",
    "        i_2 = (state[:,4:5] - state[:,4:5].mean())/state[:,4:5].std()\n",
    "        i_3 = (state[:,5:6] - state[:,5:6].mean())/state[:,5:6].std()\n",
    "        i_4 = (state[:,6:7] - state[:,6:7].mean())/state[:,6:7].std()\n",
    "        i_5 = (state[:,7:8] - state[:,7:8].mean())/state[:,7:8].std()\n",
    "        i_6 = (state[:,8:9] - state[:,8:9].mean())/state[:,8:9].std()\n",
    "        i_7 = (state[:,9:10] - state[:,9:10].mean())/state[:,9:10].std()\n",
    "        i_8 = (state[:,10:11] - state[:,10:11].mean())/state[:,10:11].std()\n",
    "        i_9 = (state[:,11:12] - state[:,11:12].mean())/state[:,11:12].std()\n",
    "        i_10 = (state[:,12:13] - state[:,12:13].mean())/state[:,12:13].std()\n",
    "\n",
    "        #senti = state[:,13:14]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        balance_obs_nml = balance_obs / networth_obs\n",
    "        networth_obs_nml = networth_obs / self.initial_balance\n",
    "        portfolio_obs_nml = portfolio_obs\n",
    "        \n",
    "        state_nml = np.concatenate((\n",
    "            market_obs_nml,\n",
    "            vol_obs_nml,\n",
    "            no_trade_nml,\n",
    "            i_1, i_2, i_3, i_4, i_5, i_6, i_7, i_8, i_9, i_10, #senti,   \n",
    "            balance_obs_nml,\n",
    "            networth_obs_nml ,\n",
    "            portfolio_obs_nml), axis=1)\n",
    "        \n",
    "        return state_nml\n",
    "\n",
    "\n",
    "    def act(self, state):\n",
    "        # Use the network to predict the next action to take, using the model\n",
    "        prediction = self.Actor.predict(np.expand_dims(state, axis=0))[0]\n",
    "        action = np.random.choice(self.action_space, p=prediction)\n",
    "        return action, prediction\n",
    "\n",
    "    def act_with_max_p(self, state):\n",
    "        # Use the network to predict the next action to take, using the model\n",
    "        prediction = self.Actor.predict(np.expand_dims(state, axis=0))[0]\n",
    "        action = self.action_space[np.argmax(prediction)]\n",
    "        return action, prediction\n",
    "  \n",
    "\n",
    "    def save(self, name=\"Crypto_trader_with_cost_v4\"):\n",
    "        # save keras model weights\n",
    "        self.Actor.Actor.save_weights(f\"/content/drive/MyDrive/{name}_Actor.h5\")\n",
    "        self.Critic.Critic.save_weights(f\"/content/drive/MyDrive/{name}_Critic.h5\")\n",
    "\n",
    "    def load(self, name=\"Crypto_trader_with_cost\"):\n",
    "        # load keras model weights\n",
    "        self.Actor.Actor.load_weights(f\"{name}_Actor.h5\")\n",
    "        self.Critic.Critic.load_weights(f\"{name}_Critic.h5\")\n",
    "        \n",
    "def Random_games(env, visualize, train_episodes = 50):\n",
    "    average_net_worth = 0\n",
    "    for episode in range(train_episodes):\n",
    "        state = env.reset()\n",
    "        while True:\n",
    "            env.render(visualize)\n",
    "            action = np.random.randint(3, size=1)[0]\n",
    "            state, reward, done = env.step(action)\n",
    "            if env.current_step == env.end_step:\n",
    "                average_net_worth += env.net_worth\n",
    "                print(\"net_worth:\", episode, env.net_worth)\n",
    "                break\n",
    "\n",
    "    print(\"average {} episodes random net_worth: {}\".format(train_episodes, average_net_worth/train_episodes))\n",
    "\n",
    "def train_agent(env, visualize=False, train_episodes = 50, training_batch_size=500):\n",
    "    ####log\n",
    "    f = open(\"trainlog_v4.txt\", \"a\")\n",
    "    f.writelines(\"The running log as of \" + str(datetime.now()) +\"\\n\")\n",
    "    f.writelines(\"episode,net_worth,average,no_orders, \\n\")\n",
    "    f.close()\n",
    "    ####\n",
    "\n",
    "    env.create_writer() # create TensorBoard writer\n",
    "    total_average = deque(maxlen=100) # save recent 100 episodes net worth\n",
    "    best_average = 0 # used to track best average net worth\n",
    "\n",
    "    pre_state = 0\n",
    "    current_state = 0\n",
    "    for episode in range(train_episodes):\n",
    "        state = env.reset(env_steps_size = training_batch_size)\n",
    "        signals = 0\n",
    "        states, actions, rewards, predictions, dones, next_states = [], [], [], [], [], []\n",
    "        g = open(\"prob_v4.txt\", \"a\")\n",
    "        for t in range(training_batch_size):\n",
    "            env.render(visualize)\n",
    "            state_nml = env.normalize_state(state)\n",
    "            action, prediction = env.act(state_nml)\n",
    "            next_state, reward, done = env.step(action) #, prediction[action])\n",
    "            next_state_nml = env.normalize_state(next_state)\n",
    "            states.append(np.expand_dims(state_nml, axis=0))\n",
    "            next_states.append(np.expand_dims(next_state_nml, axis=0))\n",
    "            action_onehot = np.zeros(env.action_space.shape[0])\n",
    "            action_onehot[action] = 1\n",
    "            actions.append(action_onehot)\n",
    "            rewards.append(reward)\n",
    "            dones.append(done)\n",
    "            predictions.append(prediction)\n",
    "            state = next_state\n",
    "            if prediction[1] > prediction[0]:\n",
    "              current_state = 1 \n",
    "            elif prediction[1] < prediction[0]:\n",
    "              current_state = 0\n",
    "            if pre_state != current_state:\n",
    "              signals += 1\n",
    "            pre_state = current_state\n",
    "\n",
    "\n",
    "            print(f\"The probability is {prediction}, net worth:{env.net_worth}, signal: {signals}\")\n",
    "\n",
    "            g.writelines(f\"{prediction}\\n\")\n",
    "            \n",
    "\n",
    "            #if t % 10000 == 0:\n",
    "            #  print(env.net_worth)\n",
    "        g.close()\n",
    "        env.replay(states, actions, rewards, predictions, dones, next_states)\n",
    "        total_average.append(env.net_worth)\n",
    "        average = np.average(total_average)\n",
    "        \n",
    "        env.writer.add_scalar('Data/average net_worth', average, episode)\n",
    "        env.writer.add_scalar('Data/episode_orders', env.episode_orders, episode)\n",
    "        \n",
    "        print(\"net worth {} {:.2f} {:.2f} {}\".format(episode, env.net_worth, average, env.episode_orders))\n",
    "        #if episode > len(total_average):\n",
    "        # if best_average < average:\n",
    "        #     best_average = average\n",
    "        #     print(\"Saving model\")\n",
    "        #     env.save()\n",
    "\n",
    "        #if episode % 10 == 0:\n",
    "\n",
    "        ####log############\n",
    "        f = open(\"trainlog_v4.txt\", \"a\")\n",
    "        f.writelines(\"{},{:.2f},{:.2f},{},\\n\".format(episode, env.net_worth, average, env.episode_orders))\n",
    "        f.close()\n",
    "        ###################\n",
    "\n",
    "        #env.save()\n",
    "\n",
    "\n",
    "def test_agent(env, visualize=True, test_episodes=10):\n",
    "    #env.load() # load the model\n",
    "    average_net_worth = 0\n",
    "    f = open(\"testlog_v4.txt\", \"a\")\n",
    "    f.writelines(\"The running log as of \" + str(datetime.now()) +\"\\n\")\n",
    "    f.writelines(\"episode,net_worth,no_orders, \\n\")\n",
    "    f.close()\n",
    "\n",
    "    for episode in range(test_episodes):\n",
    "        state = env.reset()\n",
    "        while True:\n",
    "            env.render(visualize)\n",
    "            state_nml = env.normalize_state(state)\n",
    "            action, prediction = env.act_with_max_p(state_nml)\n",
    "            state, reward, done = env.step(action)\n",
    "            if env.current_step == env.end_step:\n",
    "                average_net_worth += env.net_worth\n",
    "                print(\"net_worth:\", episode, env.net_worth, env.episode_orders)\n",
    "                break\n",
    "        f = open(\"testlog_v4.txt\", \"a\")\n",
    "        f.writelines(\"{},{:.2f},{},\\n\".format(episode, env.net_worth, env.episode_orders))\n",
    "        f.close()\n",
    "    print(\"average {} episodes agent net_worth: {}\".format(test_episodes, average_net_worth/test_episodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecdafa5f-b23f-4c4b-906f-326e0a8ae52c",
   "metadata": {
    "id": "ecdafa5f-b23f-4c4b-906f-326e0a8ae52c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('BTC_train_v4.csv').drop(columns=['taker_base_volume','taker_quote_volume'])\n",
    "df = df.rename(columns = {'open':'Open','high':'High','low':'Low','close':'Close','volume':'Volume','close_time':'Date'})\n",
    "df = df.sort_values('Date')\n",
    "\n",
    "lookback_window_size = 100\n",
    "train_df = df\n",
    "#test_df = df[-720-lookback_window_size:] # 30 days\n",
    "\n",
    "train_env = CustomEnv(train_df, lookback_window_size=lookback_window_size, initial_balance=10000)\n",
    "#test_env = CustomEnv(test_df, lookback_window_size=lookback_window_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "Uu4emSm9wyfr",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uu4emSm9wyfr",
    "outputId": "4c82e5b6-cf9f-47ab-eb1c-41e6402156bd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "731"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "AjV0mRNXKhGY",
   "metadata": {
    "id": "AjV0mRNXKhGY"
   },
   "outputs": [],
   "source": [
    "# train_env.Actor.Actor.save_weights('Crypto_trader_Actor.h5')\n",
    "# train_env.Critic.Critic.save_weights('Crypto_trader_Critic.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ccf-hCoj31kF",
   "metadata": {
    "id": "ccf-hCoj31kF"
   },
   "outputs": [],
   "source": [
    "train_env.load(\"Crypto_trader_with_cost_v4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37aaf1e1-8cca-48c5-abf3-2d71569caf45",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "37aaf1e1-8cca-48c5-abf3-2d71569caf45",
    "outputId": "7c88062d-af4e-4302-cba6-914d70902d51"
   },
   "outputs": [],
   "source": [
    "train_agent(train_env, visualize=True, train_episodes=1, training_batch_size=len(df)-lookback_window_size-1)\n",
    "#test_agent(test_env, visualize=True, test_episodes=1000)\n",
    "#Random_games(test_env, visualize=False, train_episodes = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "p7c8BBRamxGh",
   "metadata": {
    "id": "p7c8BBRamxGh"
   },
   "outputs": [],
   "source": [
    "train_env.save(\"2000Crypto_trader_with_cost_v4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OZ9-Qvan4Dvr",
   "metadata": {
    "id": "OZ9-Qvan4Dvr"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.download('LSTM_T1_with_cost_Actor.h5') \n",
    "files.download('LSTM_T1_with_cost_Critic.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wDPZ9ZMj31Bm",
   "metadata": {
    "id": "wDPZ9ZMj31Bm"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.download('LSTM_T1_Actor.h5') \n",
    "files.download('LSTM_T1_Critic.h5') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "MnayeIlu3zuI",
   "metadata": {
    "id": "MnayeIlu3zuI"
   },
   "source": [
    "#Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s00xM2FW3ee_",
   "metadata": {
    "id": "s00xM2FW3ee_"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thauxI5Y3yQ-",
   "metadata": {
    "id": "thauxI5Y3yQ-"
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('BTC_test_v4.csv')\n",
    "df_test = df_test.rename(columns = {'open':'Open','high':'High','low':'Low','close':'Close','volume':'Volume','close_time':'Date'})\n",
    "#df_test = df_test[df_test['Date']<'2021-12-31']\n",
    "df_test = df_test.sort_values('Date')\n",
    "lookback_window_size = 100\n",
    "test_df = df_test\n",
    "test_env = CustomEnv(test_df, lookback_window_size=lookback_window_size, initial_balance=10000)\n",
    "test_env.load(name=\"600Crypto_trader_with_cost_v4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hUdPzS2p5Ts8",
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "hUdPzS2p5Ts8",
    "outputId": "770d7f4b-3a6d-4f37-8669-8a2d7f8a0238"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABHgAAAI4CAYAAAARel4VAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzda5SV1Z0n/u8piotQQKiqqEPAtlGqJxIMNztgMorKUte4HOgY7Y7tpVEn2nZkGW2XSqs4iVzSSHshZaJ4jSaZ7tFEs5bG6YV4yahRbEVbSYJiEoNYUaoYLAqlLqf+L/xbE9pbxVh1eOTzeXXOPns/Z+8Dv+Xyy372U+ru7u4OAAAAAIVVVekJAAAAAPDHEfAAAAAAFJyABwAAAKDgBDwAAAAABSfgAQAAACg4AQ8AAABAwVX3x5e0t7dnwYIF6ezsTFdXV6ZPn57jjjuu5/Mbb7wx999/f2699dYkyaZNm9LY2Ji2traUy+Ucf/zxmTJlSjo7O/Od73wnv/rVr1Iul3PQQQflL/7iL5Ika9asyU033ZRyuZzDDjssc+bM6Y+lAQAAAFRcvwQ8AwcOzIIFCzJkyJB0dnbmkksuyaRJk9LQ0JD169enra1th/533HFHZsyYkcMPPzwbNmzI4sWLM2XKlPzsZz9LZ2dnli1blu3bt+ecc87J5z//+dTX1+eGG27IRRddlLq6ulx44YWZNm1axowZ0x/LAwAAAKiofrlFq1QqZciQIUmSrq6udHV1pVQqpVwu57bbbssJJ5zwjv7btm1Lkmzbti2jRo3q+ezNN99MV1dX2tvbU11dnaFDh+aFF17InnvumT322CPV1dU58MADs3r16v5YGgAAAEDF9csOniQpl8s5//zz09TUlCOOOCLjx4/PPffck6lTp+4Q4CTJsccem8suuyz33ntvtm/fnosvvjhJMn369DzxxBP5yle+kvb29px88smpqalJS0tL6urqesbX1dXl+eef79W8Nm7c+NEtEj5G6uvrs2nTpkpPA3Y5ag/6n7qDylB79JXRo0dXegoV0W8BT1VVVZYuXZq2trZcfvnlWbt2bR599NFceuml7+j78MMPZ+bMmTn66KOzbt26LF++PMuWLcsLL7yQqqqqXHvttWlra8sll1ySiRMn/kHzWLlyZVauXJkkWbJkSerr6z+K5cHHTnV1tfqAClB70P/UHVSG2oOPVr8FPG8bNmxYJkyYkOeeey5NTU2ZN29ekrcOYj7rrLOyfPnyrFq1KvPnz0+SNDQ0pKOjI62trfk//+f/ZNKkSamurs7IkSPzZ3/2Z1m/fn3q6+vT3Nzc8x3Nzc2pra191++fNWtWZs2a1fNeYgzvzr+oQGWoPeh/6g4qQ+3RV3bVHTz9cgbP66+/3nOQcnt7e5555pmMGzcuK1asSGNjYxobGzNo0KAsX748yVuF/uyzzyZJNmzYkI6OjowYMWKH9jfffDPPP/98PvWpT2WfffbJK6+8kldffTWdnZ155JFHMm3atP5YGgAAAEDF9csOns2bN6exsTHlcjnd3d2ZMWNGpk6d+p79TzrppFx77bW5++67kyRnnnlmSqVSjjzyyFxzzTU555xz0t3dnUMOOSR/8id/kiQ55ZRTsnDhwpTL5RxyyCEZO3ZsfywNAAAAoOJK3d3d3ZWeRCU5ZBnenS2zUBlqD/qfuoPKUHv0FbdoAQAAAFBIAh4AAACAghPwAAAAABScgAcAAACg4AQ8AAAAAAUn4AEAAAAoOAEPAAAAQMEJeAAAAAAKTsADAAAAUHACHgAAAICCE/AAAAAAFJyABwD42Nvtn/+50lMAAOhTAh4A4GOvesOGSk8BAKBPCXgAAAAACk7AAwAAAFBwAh4AAACAghPwAAAAABScgAcAAACg4AQ8AAAAAAUn4AEAAAAoOAEPAAAAQMEJeAAAAAAKTsADAAAAUHACHgAAAICCE/AAAAAAFJyABwAAAKDgBDwAAAAABSfgAQAAACg4AQ8AAABAwQl4AAAAAApOwAMAAABQcAIeAAAAgIIT8AAAAAAUnIAHAAAAoOAEPAAAAAAFJ+ABAAAAKDgBDwAAAEDBCXgAAAAACk7AAwAAAFBwAh4AAACAghPwAAAAABScgAcAAACg4AQ8AAAAAAUn4AEAAAAouOpKTwAAAACgv1xzzTV58sknM3LkyCxbtixJsnXr1lxxxRV57bXX8slPfjJf+9rXUlNT0zPmhRdeyEUXXZSzzz4706dPT5I88MAD+eEPf5gk+eIXv5iZM2cmSV588cU0Njamvb09kydPzty5c1Mqlfp8XXbwAAAAALuMmTNnZv78+Tu03XnnnZk4cWKuvvrqTJw4MXfeeWfPZ+VyOd/73vfy2c9+tqdt69atuf3227No0aIsWrQot99+e7Zu3ZokWbFiRU4//fRcffXVaWpqypo1a/plXQIeAAAAYJex33777bA7J0lWr16dgw8+OEly8MEHZ/Xq1T2f/eQnP8nnPve5jBgxoqdtzZo12X///VNTU5Oamprsv//+WbNmTTZv3pw33ngjDQ0NKZVKOeigg3a4Vl8S8AAAAAC7tC1btmTUqFFJkk984hPZsmVLkqSlpSWPP/54Dj/88B36t7S0pK6urud9bW1tWlpa3tFeV1eXlpaWfliBM3hSX19f6SnATqm6ulp9QAWovb4x4OyzM9jvyntQd1AZao++dMEFF/S8njVrVmbNmtXrsaVSqefMnJtvvjl//dd/naqqnX9/zC4f8GzatKnSU4CdUn19vfqAClB7fWP4lVem9dxzKz0NdlLqDipD7dFXRo8enSVLlvxBY0aOHJnNmzdn1KhR2bx5c8/tWOvXr89VV12VJHn99dfz1FNPpaqqKrW1tVm7dm3P+JaWluy3336pra1Nc3NzT3tzc3Nqa2s/glV9sF0+4AEAAAB2bdOmTcuDDz6YOXPm5MEHH8wBBxyQJGlsbOzp09jYmKlTp+bP//zPs3Xr1vzgBz/oOVj56aefzvHHH5+amprstttuWbduXcaPH5+HHnooRx55ZL+sQcADAAAA7DKuvPLKrF27Nq2trTnjjDNy3HHHZc6cObniiiuyatWqnsekv5+ampocc8wxufDCC5MkX/rSl3oObj7ttNNyzTXXpL29PZMmTcrkyZP7fE1JUuru7u7ul2/aSW3cuLHSU4Cdki2zUBlqr28MX7bMLVq8J3UHlaH26CujR4+u9BQqYuc/JQgAAACA9yXgAQAAACg4AQ8AAABAwfXLIcvt7e1ZsGBBOjs709XVlenTp+e4447r+fzGG2/M/fffn1tvvTXJW48ub2xsTFtbW8rlco4//vhMmTIlSfKb3/wm1113Xd54442USqUsXrw4gwYNyosvvpjGxsa0t7dn8uTJmTt3bs9z6wEAAAA+zvol4Bk4cGAWLFiQIUOGpLOzM5dcckkmTZqUhoaGrF+/Pm1tbTv0v+OOOzJjxowcfvjh2bBhQxYvXpwpU6akq6sry5cvz1e/+tXsvffeaW1tTXX1W0tYsWJFTj/99IwfPz6LFy/OmjVr+u2kagAAAIBK6pdbtEqlUoYMGZIk6erqSldXV0qlUsrlcm677baccMIJ7+i/bdu2JMm2bdsyatSoJG89V36vvfbK3nvvnSQZPnx4qqqqsnnz5rzxxhtpaGhIqVTKQQcdlNWrV/fH0gAAAAAqrl928CRJuVzO+eefn6amphxxxBEZP3587rnnnkydOrUnwHnbsccem8suuyz33ntvtm/fnosvvjhJ8sorr6RUKmXhwoV5/fXXc+CBB2b27NlpaWlJXV1dz/i6urq0tLT019IAAAAAKqrfAp6qqqosXbo0bW1tufzyy7N27do8+uijufTSS9/R9+GHH87MmTNz9NFHZ926dVm+fHmWLVuWrq6u/OIXv8jixYszePDgfP3rX8+4ceMydOjQXs9j5cqVWblyZZJkyZIlqa+v/6iWCB8r1dXV6gMqQO31jQFDh2aw35X3oO6gMtQefLT6LeB527BhwzJhwoQ899xzaWpqyrx585K8dRDzWWedleXLl2fVqlWZP39+kqShoSEdHR1pbW1NXV1dPv3pT2fEiBFJksmTJ+dXv/pV/st/+S9pbm7u+Y7m5ubU1ta+6/fPmjUrs2bN6nm/adOmvloqFFp9fb36gApQe31j+LZtafW78h7UHVSG2qOvjB49utJTqIh+OYPn9ddf7zlIub29Pc8880zGjRuXFStWpLGxMY2NjRk0aFCWL1+e5K1Cf/bZZ5MkGzZsSEdHR0aMGJHPfvaz+e1vf5vt27enq6srP//5zzNmzJiMGjUqu+22W9atW5fu7u489NBDmTZtWn8sDQAAAKDi+mUHz+bNm9PY2JhyuZzu7u7MmDEjU6dOfc/+J510Uq699trcfffdSZIzzzwzpVIpNTU1Oeqoo3LhhRemVCpl8uTJPY9PP+2003LNNdekvb09kyZN8gQtAAAAYJdR6u7u7q70JCpp48aNlZ4C7JRsmYXKUHt9Y/iyZWk999xKT4OdlLqDylB79BW3aAEAAABQSAIeAAAAgIIT8AAAAAAUnIAHAAAAoOAEPAAAAAAFJ+ABAAAAKDgBDwAAAEDBCXgAAAAACk7AAwAAAFBwAh4AAACAghPwAAAAABScgAcAAACg4AQ8AAAAAAUn4AEAAAAoOAEPAAAAQMEJeAAAAAAKTsADAAAAUHACHgAAAICCE/AAAAAAFJyABwAAAKDgBDwAAAAABSfgAQAAACg4AQ8AAABAwQl4AAAAAApOwAMAAABQcAIeAAAAgIIT8AAAAAAUnIAHAAAAoOAEPAAAAAAFJ+ABAAAAKDgBDwAAAEDBCXgAAAAACk7AAwAAAFBwAh4AAACAghPwAAAAABScgAcAAACg4AQ8AAAAAAUn4AEAAAAoOAEPAAAAQMEJeAAAAAAKTsADAAAAUHACHgAAAICCE/AAAAAAFJyABwAAAKDgBDwAAAAABSfgAQAAACg4AQ8AAABAwQl4AAAAAApOwAMAAABQcAIeAAAAgIIT8AAAAAAUnIAHAAAAoOAEPAAAAAAFV13pCQAAAAD0l2uuuSZPPvlkRo4cmWXLliVJtm7dmiuuuCKvvfZaPvnJT+ZrX/taampq8tOf/jR33XVXuru7s9tuu+W0007L3nvvnSRZs2ZNbrrpppTL5Rx22GGZM2dOkuTVV1/NlVdemdbW1owbNy5nnXVWqqv7Pn6xgwcAAADYZcycOTPz58/foe3OO+/MxIkTc/XVV2fixIm58847kyS77757Lr300ixbtizHHHNMrrvuuiRJuVzODTfckPnz5+eKK67Iww8/nA0bNiRJbrvtthx11FFZvnx5hg0bllWrVvXLugQ8AAAAwC5jv/32S01NzQ5tq1evzsEHH5wkOfjgg7N69eokyZ/92Z/19B0/fnyam5uTJC+88EL23HPP7LHHHqmurs6BBx6Y1atXp7u7O88991ymT5+e5K0w6e1r9bV+uUWrvb09CxYsSGdnZ7q6ujJ9+vQcd9xxPZ/feOONuf/++3PrrbcmSTZt2pTGxsa0tbWlXC7n+OOPz5QpU3r6b9q0KV/72tdy7LHH5r/9t/+W5L23RgEAAAC8ny1btmTUqFFJkk984hPZsmXLO/qsWrUqkydPTpK0tLSkrq6u57O6uro8//zzaW1tzdChQzNgwIAkSW1tbVpaWvphBf0U8AwcODALFizIkCFD0tnZmUsuuSSTJk1KQ0ND1q9fn7a2th3633HHHZkxY0YOP/zwbNiwIYsXL94h4Lnlllt6ftTk/22Nuuiii1JXV5cLL7ww06ZNy5gxYz5wbvX19R/dQuFjpLq6Wn1ABai9vjHg7LMz2O/Ke1B3UBlqj750wQUX9LyeNWtWZs2a1euxpVIppVJph7Znn302999/f77+9a9/ZHP8qPVLwFMqlTJkyJAkSVdXV7q6ulIqlVIul3Pbbbdl3rx5efzxx3fov23btiTJtm3belK0JHn88cez++67Z/DgwT1tv781KknP1qjeBDybNm36SNYIHzf19fXqAypA7fWN4VdemdZzz630NNhJqTuoDLVHXxk9enSWLFnyB40ZOXJkNm/enFGjRmXz5s0ZMWJEz2e/+c1vcu211+bCCy/M8OHDk7y1M+ft27WSpLm5ObW1tRk+fHi2bduWrq6uDBgwIC0tLamtrf1oFvYB+u0pWuVyOeeff36amppyxBFHZPz48bnnnnsyderUHQKcJDn22GNz2WWX5d5778327dtz8cUXJ0nefPPN3HXXXbn44ovz4x//uKf/e22NejcrV67MypUrkyRLliyRGMN78C8qUBlqr28MGDrUDh7ek7qDylB77EymTZuWBx98MHPmzMmDDz6YAw44IMlbm0Iuv/zyfPWrX83o0aN7+u+zzz555ZVX8uqrr6a2tjaPPPJI5s2bl1KplAkTJuRnP/tZPv/5z+eBBx7ItGnT+mUN/RbwVFVVZenSpWlra8vll1+etWvX5tFHH82ll176jr4PP/xwZs6cmaOPPjrr1q3L8uXLs2zZsvzLv/xLjjrqqJ7dQB/Gf9yaJTGGd+dfVKAy1F7fGL5tW1r9rrwHdQeVofboK78fxLybK6+8MmvXrk1ra2vOOOOMHHfccZkzZ06uuOKKrFq1qucx6Uly++23Z+vWrbn++uuTJAMGDMiSJUsyYMCAnHLKKVm4cGHK5XIOOeSQjB07Nkny13/917nyyivzP//n/8yf/umf5tBDD+3bBf//+i3geduwYcMyYcKEPPfcc2lqasq8efOSvHUQ81lnnZXly5dn1apVPY8sa2hoSEdHR1pbW/PCCy/ksccey/e+9720tbWlVCpl0KBBGTdu3LtujQIAAAD4fWefffa7tl9yySXvaDvjjDNyxhlnvGv/KVOm7HBe8Nv22GOPLF68+I+b5IfQLwHP66+/ngEDBmTYsGFpb2/PM888k9mzZ2fFihU9fU488cQsX748yVtJ7rPPPpuZM2dmw4YN6ejoyIgRI3Y4zOhf/uVfMmTIkBx55JHp6up6161RAAAAALuCfgl4Nm/enMbGxpTL5XR3d2fGjBmZOnXqe/Y/6aSTcu211+buu+9Okpx55pnvOMH6973f1igAAACAj7tSd3d3d6UnUUkbN26s9BRgp+SeaKgMtdc3hi9b5ilavCd1B5Wh9ugrH3QGz8dVVaUnAAAAAMAfR8ADAAAAUHACHgAAAICCE/AAAAAAFJyABwAAAKDgBDwAAAAABSfgAQAAACg4AQ8AAABAwQl4AAAAAApOwAMAAABQcAIeAAAAgIIT8AAAAAAUnIAHAAAAoOAEPAAAAAAFJ+ABAAAAKDgBDwAAAEDBCXgAAAAACk7AAwAAAFBwAh4AAACAghPwAAAAABScgAcAAACg4AQ8AAAAAAUn4AEAAAAoOAEPAAAAQMEJeAAAAAAKTsADAAAAUHACHgAAAICCE/AAAAAAFJyABwAAAKDgBDwAAAAABSfgAQAAACg4AQ8AAABAwQl4AAAAAApOwAMAAABQcAIeAAAAgIIT8AAAAAAUnIAHAAAAoOAEPAAAAAAFJ+ABAAAAKDgBDwAAAEDBCXgAAAAACk7AAwAAAFBwAh4AAACAghPwAAAAABScgAcAAACg4AQ8AAAAADuB1tbWPPTQQ7nrrruSJC0tLWlubu7VWAEPAAAAQIWtXbs2Z599dn7605/mjjvuSJI0NTVlxYoVvRov4AEAAACosJtvvjlnn312/uEf/iEDBgxIkuy7775Zv359r8YLeAAAAAAq7LXXXsvEiRN3aKuurk5XV1evxgt4AAAAACpszJgxWbNmzQ5t//7v/5699tqrV+Or+2JSAAAAAPTeiSeemG9+85uZPHly2tvbc9111+Xf/u3fct555/VqvIAHAAAAoMIaGhqydOnS/PSnP82QIUNSX1+fRYsWpa6urlfjBTwAAAAAFdbR0ZERI0Zk9uzZPW2dnZ3p6OjIwIEDP3C8M3gAAAAAKuyyyy7Liy++uEPbiy++mIULF/ZqvIAHAAAAoMJeeumljB8/foe2fffdN7/5zW96Nf4PCnhaW1vz0EMP5a677kqStLS0pLm5+Q+5BAAAAAD/wdChQ7Nly5Yd2rZs2ZLBgwf3anyvz+BZu3Ztli1blnHjxuWXv/xlZs+enaampvz4xz/OBRdc8L5j29vbs2DBgnR2dqarqyvTp0/Pcccd1/P5jTfemPvvvz+33nprkmTTpk1pbGxMW1tbyuVyjj/++EyZMiXPPPNMvve976WzszPV1dU58cQT85nPfCbJW9uWGhsb097ensmTJ2fu3LkplUq9XR4AAABAxXzuc5/LVVddlblz52aPPfbI7373u9xyyy2ZMWNGr8b3OuC5+eabc/bZZ2fixImZO3dukre2Cq1fv/4Dxw4cODALFizIkCFD0tnZmUsuuSSTJk1KQ0ND1q9fn7a2th3633HHHZkxY0YOP/zwbNiwIYsXL86UKVMyfPjwnH/++amtrc1LL72UhQsX5tprr02SrFixIqeffnrGjx+fxYsXZ82aNZk8eXJvlwcAAABQMX/1V3+V7373u5k/f346OjoyaNCgzJw5M1/+8pd7Nb7XAc9rr72WiRMn7ji4ujpdXV0fOLZUKmXIkCFJkq6urnR1daVUKqVcLue2227LvHnz8vjjj+/Qf9u2bUmSbdu2ZdSoUUmSP/3TP+3pM3bs2LS3t6ejoyNbt27NG2+8kYaGhiTJQQcdlNWrVwt4AAAAgEIYNGhQTjvttJx66qlpbW3N8OHD/6A7k3od8IwZMyZr1qzJpEmTetr+/d//PXvttVevxpfL5Zx//vlpamrKEUcckfHjx+eee+7J1KlTewKctx177LG57LLLcu+992b79u25+OKL33G9xx57LOPGjcvAgQPT0tKyw3Ph6+rq0tLS8q7zWLlyZVauXJkkWbJkSerr63s1f9jVVFdXqw+oALXXNwYMHZrBflfeg7qDylB78E7btm3Lxo0b8+abb+7Q/vbxNO+n1wHPiSeemG9+85uZPHly2tvbc9111+Xf/u3fct555/VqfFVVVZYuXZq2trZcfvnlWbt2bR599NFceuml7+j78MMPZ+bMmTn66KOzbt26LF++PMuWLUtV1VtnQv/2t7/N9773vfzDP/xDb6ffY9asWZk1a1bP+02bNv3B14BdQX19vfqAClB7fWP4tm1p9bvyHtQdVIbao6+MHj260lP4UB544IHccMMNGTJkSAYNGtTTXiqV8q1vfesDx/c64GloaMjSpUvz05/+NEOGDEl9fX0WLVq0w86Z3hg2bFgmTJiQ5557Lk1NTZk3b16Stw5iPuuss7J8+fKsWrUq8+fP7/nejo6OtLa2ZuTIkWlubs7ll1+ev/u7v8uee+6ZJKmtrd3haV7Nzc2pra39g+YFAAAAUCk/+MEPcs4553zo42Z6HfB0dHRkxIgRmT17dk9bZ2dnOjo6MnDgwPcd+/rrr2fAgAEZNmxY2tvb88wzz2T27NlZsWJFT58TTzwxy5cvT/JWkvvss89m5syZ2bBhQ893t7W1ZcmSJTn++OPzn//zf+4ZO2rUqOy2225Zt25dxo8fn4ceeihHHnlkr38EAAAAYNdwzTXX5Mknn8zIkSOzbNmyJMnWrVtzxRVX5LXXXssnP/nJfO1rX0tNTU26u7tz00035amnnsrgwYNz5plnZty4cUne2nHzwx/+MEnyxS9+MTNnzkzy4Z/yXS6X89nPfvZDr6uqtx0vu+yyvPjiizu0vfjii1m4cOEHjt28eXP+x//4H/n7v//7XHjhhdl///0zderU9+x/0kkn5b777st5552Xq666KmeeeWZKpVLuvffeNDU15fbbb895552X8847r+cZ8aeddlquvfbazJs3L3vssYcDlgEAAIB3mDlzZs9dQ2+78847M3HixFx99dWZOHFi7rzzziTJU089laamplx99dX5yle+kuuvvz7JW4HQ7bffnkWLFmXRokW5/fbbs3Xr1iT/7ynfV199dZqamrJmzZpezWv27Nm54447Ui6XP9S6er2D56WXXsr48eN3aNt3333zm9/85gPH/smf/En+8R//8X373HrrrT2vx4wZk2984xvv6HPMMcfkmGOOedfx++yzT0/yBgAAAPBu9ttvv7z66qs7tK1evbrnjOCDDz44l156aU444YQ88cQTOeigg1IqldLQ0JC2trZs3rw5zz33XPbff//U1NQkSfbff/+sWbMmEyZM+NBP+b777rvzf//v/82Pf/zjnuu+7dvf/vYHju91wDN06NBs2bIln/jEJ3ratmzZksGDB/f2EgAAAAA7nS1btvQ84fsTn/hEz91CLS0tOzzt7e2ndv/Hp3nX1ta+a/v7PeX7PzrrrLP+qDX0OuD53Oc+l6uuuipz587NHnvskd/97ne55ZZbMmPGjD9qApXmsXzw7jy2EipD7fWNAWef7THpvCd1B5Wh9uhLF1xwQc/r//g07Q9SKpV6dWbOR22//fb7o8b3OuD5q7/6q3z3u9/N/Pnz09HRkUGDBmXmzJn58pe//EdNoNI8lg/encdWQmWovb4x/Mor03ruuZWeBjspdQeVofboK6NHj86SJUv+oDEjR47M5s2bM2rUqGzevDkjRoxI8tbOnN//e/r2U7tra2uzdu3anvaWlpbst99+f/RTvn/961/n5z//eVpbW9Pd3d3T/pd/+ZcfOLbXAc+gQYNy2mmn5dRTT01ra2uGDx9ekUQLAAAA4KM0bdq0PPjgg5kzZ04efPDBHHDAAT3t9957bz7/+c/n+eefz9ChQzNq1KhMmjQpP/jBD3oOVn766adz/PHHp6am5kM/5XvlypW55ZZbes7zmTRpUp555plMmzatV+PfN+B59dVXs/vuuydJfve73+3w2RtvvNHzeo899ujVlwEAAABU0pVXXpm1a9emtbU1Z5xxRo477rjMmTMnV1xxRVatWtXzmPQkmTx5cp588snMmzcvgwYNyplnnpkkqampyTHHHJMLL7wwSfKlL32p52Dk0047Lddcc03a29szadKkXj/l+6677sr8+fPz6U9/OnPnzs15552Xp556Kg8//HCvxrSLptMAACAASURBVJe6f3/Pz39w0kkn5bvf/W6S998O9M///M+9+rKd0caNGys9hT9YzbJlqf71rys9DT7mBg8enO3bt1d6GrDLUXt9Y+Daten4I+9r5+NL3UFlqL2dX+fee2drAW9xHj16dKWn8KGcfPLJueWWW5Ikp5xySq6//vpUVVVl7ty5uemmmz5w/Pvu4Hk73EmKHeJ83FT/+tepfuGFSk+Dj7lSdXWqOzsrPQ3Y5ai9vlHV0uK/nbwndQeVofZgR7W1tT13Uv2n//Sf8sQTT2T48OGpru7d6TpVvelULpdz1llnpaOj44+aLAAAAADvNHv27Lz88stJ3rrla/ny5fn617+eY489tlfjexUDVVVVpaqqKu3t7Rk4cOCHny0AAAAA7zBz5sye15MnT85NN92Uzs7ODBkypFfje/0Urf/6X/9rrrzyyvzFX/xFamtrd3iClkOWAQAAAP4w5XL5PT+rqqrKoEGDUi6XU1X1wTdg9TrgufHGG5MkzzzzzDs+cz4PAAAAwB/my1/+cq/69SZ3+cCAZ/v27bnjjjsyefLkjBs3LnPmzMmgQYN6NQEAAAAA3t23vvWtj+xaHxjw3HDDDVm/fn0mT56cxx57LFu3bs0pp5zykU0AAAAAYFf0yU9+8iO71gcGPGvWrMk3v/nNjBo1KkceeWQWLFgg4AEAAAD4iD3xxBNZu3ZtXn/99R3av/rVr37g2A88pWf79u0ZNWpUkqS+vj7btm37kNMEAAAA4N38r//1v3LdddelXC7nZz/7WWpqavL0009n6NChvRr/gTt4urq68uyzz/a8L5fLO7xPks985jN/4LQBAAAAeNv999+fiy66KHvttVceeOCB/M3f/E2+8IUv5I477ujV+A8MeEaOHJlvf/vbPe9ramp2eF8qlT7SQ4EAAAAAdjVtbW3Za6+9kiTV1dXp7OzMvvvum7Vr1/Zq/AcGPI2NjX/cDAEAAAB4X3vuuWd++9vfZuzYsRk7dmz+9V//NTU1NampqenV+A8MeAAAAADoW3/5l3+Z1tbWJMnxxx+fq6++Om+++WZOPfXUXo0X8AAAAABU2JQpU3pe77777jnhhBPyqU99KmPGjOnVeAEPAAAAQIW0tLTkxhtvzIYNG9LQ0JCjjz46CxYsSFVVVdra2vLVr341n//85z/wOh/4mHQAAAAA+sZ1112XYcOG5eSTT053d3cWLlyYM844I9dff33OOeec/OhHP+rVdQQ8AAAAABWybt26/Pf//t8zefLknHbaadmyZUsOOOCAJMkBBxyQ1157rVfXEfAAAAAAVEhXV1eqq986QWfw4MEZMmRISqXSH3wdZ/AAAAAAVEhXV1eeffbZnvflcvkd73tDwAMAAABQISNHjsy3v/3tnvc1NTU7vB8xYkSvriPgAQAAAKiQxsbGj+Q6zuABAAAAKDgBDwAAAEDBCXgAAAAACk7AAwAAAFBwAh4AAACAghPwAAAAABScgAcAAACg4AQ8AAAAAAUn4AEAAAAoOAEPAAAAQMEJeAAAAAAKTsADAAAAUHACHgAAAICCE/AAAAAAFJyABwAAAKDgBDwAAAAABSfgAQAAACg4AQ8AAABAwQl4AAAAAApOwAMAAABQcAIeAAAAgIIT8AAAAAAUnIAHAAAAoOAEPAAAAAAFJ+ABAAAAKDgBDwAAAEDBCXgAAAAACk7AAwAAAFBw1f3xJe3t7VmwYEE6OzvT1dWV6dOn57jjjuv5/MYbb8z999+fW2+9NUmyadOmNDY2pq2tLeVyOccff3ymTJmSJPnRj36UVatWpaqqKnPnzs2kSZOSJGvWrMlNN92Ucrmcww47LHPmzOmPpQEAAABUXL8EPAMHDsyCBQsyZMiQdHZ25pJLLsmkSZPS0NCQ9evXp62tbYf+d9xxR2bMmJHDDz88GzZsyOLFizNlypRs2LAhjzzySP7pn/4pmzdvzje+8Y1cddVVSZIbbrghF110Uerq6nLhhRdm2rRpGTNmTH8sDwAAAKCi+uUWrVKplCFDhiRJurq60tXVlVKplHK5nNtuuy0nnHDCO/pv27YtSbJt27aMGjUqSbJ69eoceOCBGThwYHbffffsueeeeeGFF/LCCy9kzz33zB577JHq6uoceOCBWb16dX8sDQAAAKDi+mUHT5KUy+Wcf/75aWpqyhFHHJHx48fnnnvuydSpU3sCnLcde+yxueyyy3Lvvfdm+/btufjii5MkLS0tGT9+fE+/2tratLS0JEnq6up62uvq6vL888/3w6oAAAAAKq/fAp6qqqosXbo0bW1tufzyy7N27do8+uijufTSS9/R9+GHH87MmTNz9NFHZ926dVm+fHmWLVv2kcxj5cqVWblyZZJkyZIlqa+v/0iu25+q9tsvpcGDKz0NPu5KpQzo7q70LGDXo/b6RKlczoAJEyo9DXZW6g4qQ+3t9Kr22aeQ/8+8q+q3gOdtw4YNy4QJE/Lcc8+lqakp8+bNS/LWQcxnnXVWli9fnlWrVmX+/PlJkoaGhnR0dKS1tTW1tbVpbm7uuVZLS0tqa2uTZIf25ubmnvb/aNasWZk1a1bP+02bNn3ka+xzf/u3lZ4Bu4D6+vpi1gcUnNrrG8OXLUvruedWehrspNQdVIbaK4gC/hmNHj260lOoiH45g+f111/vOUi5vb09zzzzTMaNG5cVK1aksbExjY2NGTRoUJYvX57krUJ/9tlnkyQbNmxIR0dHRowYkWnTpuWRRx5JR0dHXn311bzyyivZd999s88+++SVV17Jq6++ms7OzjzyyCOZNm1afywNAAAAoOL6ZQfP5s2b09jYmHK5nO7u7syYMSNTp059z/4nnXRSrr322tx9991JkjPPPDOlUiljx47NjBkzcs4556SqqiqnnnpqqqreyqhOOeWULFy4MOVyOYccckjGjh3bH0sDAAAAqLhSd/eufdPjxo0bKz0F2CnZMguVofb6hlu0eD/qDipD7dFX3KIFAAAAQCEJeAAAAAAKTsADAAAAUHACHgAAAICCE/AAAAAAFJyABwAAAKDgBDwAAAAABVdd6QkAAAAA9Kd77rkn9913X7q7u3PYYYflqKOOyq9//eusWLEi7e3tGTBgQE477bTsu+++6e7uzk033ZSnnnoqgwcPzplnnplx48YlSR544IH88Ic/TJJ88YtfzMyZMyu2Jjt4AAAAgF3GSy+9lPvuuy+LFi3K0qVL8+STT6apqSm33XZbvvSlL2Xp0qU57rjjcttttyVJnnrqqTQ1NeXqq6/OV77ylVx//fVJkq1bt+b222/PokWLsmjRotx+++3ZunVrxdYl4AEAAAB2GS+//HL23XffDB48OAMGDMinP/3pPPbYYymVSnnjjTeSJNu2bcuoUaOSJE888UQOOuiglEqlNDQ0pK2tLZs3b86aNWuy//77p6amJjU1Ndl///2zZs2aiq1LwAMAAADsMsaOHZtf/OIXaW1tzfbt2/PUU0+lubk5J598cm699db87d/+bW699dYcf/zxSZKWlpbU19f3jK+rq0tLS0taWlpSV1fX015bW5uWlpZ+X8/bdvkzeH7/Dwn4f6qrq9UHVIDa6xsDzj47g/2uvAd1B5Wh9uhLF1xwQc/rWbNmZdasWT3vx4wZk9mzZ+eyyy7LkCFDsvfee6eqqir/+q//mpNPPjnTp0/PI488ku985zu5+OKLKzH9D2WXD3g2bdpU6SnATqm+vl59QAWovb4x/Mor03ruuZWeBjspdQeVofboK6NHj86SJUvet8+hhx6aQw89NEny/e9/P3V1dfn+97+fuXPnJklmzJiRa6+9NslbO3N+/+9qc3NzamtrU1tbm7Vr1/a0t7S0ZL/99vuol9NrbtECAAAAdilbtmxJ8tamj8cffzxf+MIXdghsnn322ey5555JkmnTpuWhhx5Kd3d31q1bl6FDh2bUqFGZNGlSnn766WzdujVbt27N008/nUmTJlVsTbv8Dh4AAABg17Js2bK0tramuro6p556aoYNG5bTTz89N910U8rlcgYOHJjTTz89STJ58uQ8+eSTmTdvXgYNGpQzzzwzSVJTU5NjjjkmF154YZLkS1/6Umpqaiq2plJ3d3d3xb59J7Bx48ZKTwF2SrbMQmWovb4xfNkyt2jxntQdVIbao6+MHj260lOoCLdoAQAAABScgAcAAACg4AQ8AAAAAAUn4AEAAAAoOAEPAAAAQMEJeAAAAAAKTsADAAAAUHACHgAAAICCE/AAAAAAFJyABwAAAKDgBDwAAAAABSfgAQAAACg4AQ8AAABAwQl4AAAAAApOwAMAAABQcAIeAAAAgIIT8AAAAAAUnIAHAAAAoOAEPAAAAAAFJ+ABAAAAKDgBDwAAAEDBCXgAAAAACk7AAwAAAFBwAh4AAACAghPwAAAAABScgAcAAACg4AQ8AAAAAAUn4AEAAAAoOAEPAAAAQMEJeAAAAAAKTsADAAAAUHACHgAAAICCE/AAAAAAFJyABwAAAKDgBDwAAAAABSfgAQAAACg4AQ8AAABAwQl4AAAAAApOwAMAAABQcAIeAAAAgIKr7o8vaW9vz4IFC9LZ2Zmurq5Mnz49xx13XM/nN954Y+6///7ceuutSZKbb745zz33XM/YLVu25Oabb06S3HbbbXnyySfT3d2diRMnZu7cuSmVSnnxxRfT2NiY9vb2TJ48uacdAAAA4OOuXwKegQMHZsGCBRkyZEg6OztzySWXZNKkSWloaMj69evT1ta2Q/+/+Zu/6Xn9k5/8JL/61a+SJL/85S/zy1/+MpdffnmS5OKLL87atWszYcKErFixIqeffnrGjx+fxYsXZ82aNZk8eXJ/LA8AAACgovrlFq1SqZQhQ4YkSbq6utLV1ZVSqZRyuZzbbrstJ5xwwnuOffjhh/OFL3yh5zrt7e3p7OxMR0dHurq6MnLkyGzevDlvvPFGGhoaUiqVctBBB2X16tX9sTQAAACAiuuXHTxJUi6Xc/7556epqSlHHHFExo8fn3vuuSdTp07NqFGj3nXMa6+9lldffTWf+cxnkiQNDQ2ZMGFCvvKVr6S7uztHHnlkxowZk/Xr16eurq5nXF1dXVpaWvplXQAAAACV1m8BT1VVVZYuXZq2trZcfvnlWbt2bR599NFceuml7znm4YcfzvTp01NV9dZGo6amprz88sv5zne+kyT5xje+kZ///OcZNGhQr+excuXKrFy5MkmyZMmS1NfXf/hFwcdYdXW1+oAKUHt9Y8DQoRnsd+U9qDuoDLUHH61+C3jeNmzYsEyYMCHPPfdcmpqaMm/evCRvHaZ81llnZfny5T19H3nkkZx66qk97x9//PGMHz++53avyZMnZ926dTnooIPS3Nzc06+5uTm1tbXv+v2zZs3KrFmzet5v2rTpI10ffFzU19erD6gAtdc3hm/blla/K+9B3UFlqD36yujRoys9hYrolzN4Xn/99Z6DlNvb2/PMM89k3LhxWbFiRRobG9PY2JhBgwbtEO68/PLLaWtrS0NDQ09bfX19fv7zn6erqyudnZ1Zu3ZtPvWpT2XUqFHZbbfdsm7dunR3d+ehhx7KtGnT+mNpAAAAABXXLzt4Nm/enMbGxpTL5XR3d2fGjBmZOnXq+455+OGHc+CBB+7wqPPp06fn2Wefzd///d8nSSZNmtQT5Jx22mm55ppr0t7enkmTJnmCFgAAALDLKHV3d3dXehKVtHHjxkpPAXZKtsxCZai9vjF82bK0nntupafBTkrdQWWoPfqKW7QAAAAAKCQBDwAAAEDBCXgAAAAACk7AAwAAAFBwAh4AAACAghPwAAAAABScgAcAAACg4AQ8AAAAAAUn4AEAAAAoOAEPAAAAQMEJeAAAAAAKTsADAAAAUHACHgAAAICCE/AAAAAAFJyABwAAAKDgBDwAAAAABVdd6QkAAAAA9Kd77rkn9913X7q7u3PYYYflqKOOSpL85Cc/yf/+3/87VVVVmTJlSk444YQkyY9+9KOsWrUqVVVVmTt3biZNmpQkWbNmTW666aaUy+UcdthhmTNnTsXWJOABAAAAdhkvvfRS7rvvvixatCjV1dVZtGhRpk6dmk2bNuWJJ57I0qVLM3DgwGzZsiVJsmHDhjzyyCP5p3/6p2zevDnf+MY3ctVVVyVJbrjhhlx00UWpq6vLhRdemGnTpmXMmDEVWZeABwAAANhlvPzyy9l3330zePDgJMmnP/3pPPbYY1m/fn1mz56dgQMHJklGjhyZJFm9enUOPPDADBw4MLvvvnv23HPPvPDCC0mSPffcM3vssUeS5MADD8zq1asrFvA4gwcAAADYZYwdOza/+MUv0tramu3bt+epp55Kc3NzXnnllfziF7/I/Pnzs2DBgp4Qp6WlJXV1dT3ja2tr09LS8o72urq6tLS09Pt63rbL7+Cpr6+v9BRgp1RdXa0+oALUXt8YcPbZGex35T2oO6gMtUdfuuCCC3pez5o1K7Nmzep5P2bMmMyePTuXXXZZhgwZkr333jtVVVUpl8vZunVrFi5cmPXr1+eKK67It771rUpM/0PZ5QOeTZs2VXoKsFOqr69XH1ABaq9vDL/yyrSee26lp8FOSt1BZag9+sro0aOzZMmS9+1z6KGH5tBDD02SfP/7309dXV1efvnl/Pmf/3lKpVL23XffVFVVpbW1NbW1tWlubu4Z29LSktra2iTZob25ubmnvRLcogUAAADsUt4+QHnTpk15/PHH84UvfCEHHHBAnnvuuSTJxo0b09nZmeHDh2fatGl55JFH0tHRkVdffTWvvPJK9t133+yzzz555ZVX8uqrr6azszOPPPJIpk2bVrE17fI7eAAAAIBdy7Jly9La2prq6uqceuqpGTZsWA499NBcc801Offcc1NdXZ2/+7u/S6lUytixYzNjxoycc845qaqqyqmnnpqqqrf2y5xyyilZuHBhyuVyDjnkkIwdO7Ziayp1d3d3V+zbdwIbN26s9BRgp2TLLFSG2usbw5ctc4sW70ndQWWoPfrK6NGjKz2FinCLFgAAAEDBCXgAAAAACk7AAwAAAFBwAh4AAACAghPwAAAAABScgAcAAACg4AQ8AAAAAAUn4AEAAAAoOAEPAAAAQMEJeID/r737DbKyvM8Hfp3dZYEFFJblTxCpLH9KgjpaiALGPyFb40RfGCc1bdAZ86LpVINNp81I0mlNM9MZJzGDSmidVgtJ0JimrTY16bTZQUMVaVGIREjUjdpIEJZlQVgWuu7u+b1wsr84jRlM4Dz7LJ/PGzmH8yzf+8Xlmbn2vp8HAACAklPwAAAAAJScggcAAACg5BQ8AAAAACWn4AEAAAAoOQUPAAAAQMkpeAAAAABKTsEDAAAAUHIKHgAAAICSU/AAAAAAlJyCBwAAAKDkFDwAAAAAJafgAQAAACg5BQ8AAABAySl4AAAAAEpOwQMAAABQcgoeAAAAgJJT8AAAAACUnIIHAAAAoOQUPAAAAAAlp+ABAAAAKDkFDwAAAEDJNdTiH+nr68vtt9+e/v7+DAwMZMmSJbn++uuH/v7v//7v89hjj+VrX/takmT9+vXZuXPn0LWvv/561q9fnyTp6urKvffemwMHDiRJPvOZz2Tq1Knp7OzMXXfdlSNHjqS1tTUrV65MQ0NNlgcAAABQqJo0IKNGjcrtt9+eMWPGpL+/P3/xF3+RCy64IPPnz8+Pf/zjHD169C2fv+mmm4b+/G//9m95+eWXh15/+ctfznXXXZfzzz8/x48fT6VSSZJs2LAhV199dS655JL87d/+bTZu3Jgrr7yyFssDAIa5/pkzix4BAOCUqskRrUqlkjFjxiRJBgYGMjAwkEqlksHBwWzYsCE33HDD21775JNP5n3ve1+SZPfu3RkYGMj555+fJBkzZkxGjx6darWanTt3ZsmSJUmSK664Ilu3bj3FqwIAyuLYRz9a9AgAAKdUzc4wDQ4O5rbbbsvevXvzwQ9+MPPmzct3vvOdLFq0KJMmTfqF1+zfvz+dnZ0599xzkyR79uzJuHHjcuedd6azszPnnXdeVqxYkZ6enjQ1NaW+vj5J0tzcnO7u7l/4M9vb29Pe3p4kueOOO9LS0nIKVgvl19DQIB9QANmD2pM7KIbswclVs4Knrq4uX/ziF3P06NHceeed2bVrV5566ql87nOfe9trnnzyySxZsiR1dW9uNBocHMwPf/jDfOELX0hLS0tWr16dxx9/PIsXLz7hOdra2tLW1jb0uqur61deE4xkLS0t8gEFkD2oPbmDYsgep8qMGTOKHqEQNX+K1rhx47Jw4cLs3Lkze/fuza233ppbbrklfX19Wbly5Vs+u3nz5lxyySVDr5ubm3POOedk2rRpqa+vz0UXXZSXXnopEyZMSG9vbwYGBpIk3d3daW5urum6AAAAAIpSk4Ln8OHDQzdS7uvry44dO9La2pq/+7u/y9q1a7N27do0NjZmzZo1Q9f89Kc/zdGjRzN//vyh9+bOnZve3t4cPnw4SfLcc89l5syZqVQqWbhwYbZs2ZIk73hXDwAAAECZ1eSI1sGDB7N27doMDg6mWq1m6dKlWbRo0S+95sknn8yyZcuGnpKVvHnM68Ybb8znP//5VKvVtLa2Dh23WrFiRe6666489NBDmT17dpYvX35K1wQAAAAwXFSq1Wq16CGKtGfPnqJHgGHJmWgohuxB7ckdFEP2OFXcgwcAAACAUlLwAAAAAJScggcAAACg5BQ8AAAAACWn4AEAAAAoOQUPAAAAQMkpeAAAAABKTsEDAAAAUHIKHgAAAICSU/AAAAAAlFylWq1Wix4CAAAAgF+dHTzAL7Rq1aqiR4DTkuxB7ckdFEP24ORS8AAAAACUnIIHAAAAoOQUPMAv1NbWVvQIcFqSPag9uYNiyB6cXG6yDAAAAFBydvAAAAAAlJyCBwAAAKDkFDwAAAAAJafgAQAAACg5BQ8AAABAySl4AAAAAEpOwQMAAABQcgoeAAAAgJJT8AAAAACUXEPRAxRtz549RY8Aw1JLS0u6urqKHgNOO7IHtSd3UAzZ41SZMWNG0SMUwg4eAAAAgJJT8AAAAACUnIIHAAAAoOQUPAAAAAAlp+ABAAAAKDkFDwAAAEDJDevHpA8ODmbVqlVpbm7OqlWr0tnZmbvuuitHjhxJa2trVq5cmYaGhrzxxhv58pe/nJdeeikTJkzIpz71qUydOrXo8QEAAABqYljv4PnOd76Ts846a+j1hg0bcvXVV2fNmjUZN25cNm7cmCTZuHFjxo0blzVr1uTqq6/OAw88UNTIAAAAADU3bAueAwcOZNu2bfnABz6QJKlWq9m5c2eWLFmSJLniiiuydevWJMnTTz+dK664IkmyZMmSPPfcc6lWq4XMDQAAAFBrw7bgWb9+fW644YZUKpUkyZEjR9LU1JT6+vokSXNzc7q7u5Mk3d3dmTx5cpKkvr4+TU1NOXLkSDGDAwAAANTYsLwHzzPPPJMzzzwzra2t2blz50n92e3t7Wlvb0+S3HHHHWlpaTmpPx9GioaGBvmAAsge1J7cQTFkD06uYVnwPP/883n66aezffv29PX15dixY1m/fn16e3szMDCQ+vr6dHd3p7m5Ocmbu3kOHDiQyZMnZ2BgIL29vZkwYcIv/NltbW1pa2sbet3V1VWTNUHZtLS0yAcUQPag9uQOiiF7nCozZswoeoRCDMsjWh/72Mdy7733Zu3atfnUpz6Vc889N7feemsWLlyYLVu2JEkef/zxLF68OEmyaNGiPP7440mSLVu2ZOHChUNHuwAAAABGumFZ8LydFStW5NFHH83KlSvT09OT5cuXJ0mWL1+enp6erFy5Mo8++mhWrFhR8KQAAAAAtVOpnuaPm9qzZ0/RI8CwZMssFEP2oPbkDoohe5wqjmgBAAAAUEoKHgAAAICSU/AAAAAAlJyCBwAAAKDkFDwAAAAAJafgAQAAACg5BQ8AAABAySl4AAAAAEpOwQMAAABQcgoeAAAAgJJT8AAAAACUnIIHAAAAoOQUPAAAAAAlp+ABAAAAKDkFDwAAAEDJKXgAAAAASk7BAwAAAFByCh4AAACAklPwAAAAAJRcQ9EDvJ2urq6sXbs2hw4dSqVSSVtbWz70oQ+lp6cnq1evzv79+zNlypT88R//ccaPH59qtZp169Zl+/btGT16dG6++ea0trYWvQwAAACAU27Y7uCpr6/PjTfemNWrV+ev/uqv8u///u/ZvXt3HnnkkZx33nm55557ct555+WRRx5Jkmzfvj179+7NPffck0984hO57777Cl4BAAAAQG0M24Jn0qRJQztwxo4dm7POOivd3d3ZunVrLr/88iTJ5Zdfnq1btyZJnn766Vx22WWpVCqZP39+jh49moMHDxY2PwAAAECtDNsjWj+vs7MzL7/8cubOnZvXX389kyZNSpJMnDgxr7/+epKku7s7LS0tQ9dMnjw53d3dQ5/9mfb29rS3tydJ7rjjjrdcA/x/DQ0N8gEFkD2oPbmDYsgenFzDvuA5fvx4vvSlL+Wmm25KU1PTW/6uUqmkUqm8o5/X1taWtra2odddXV0nZU4YaVpaWuQDCiB7UHtyB8WQPU6VGTNmFD1CIYbtEa0k6e/vz5e+9KVceumlufjii5MkZ5555tDRq4MHD+aMM85IkjQ3N7/lfw4HDhxIc3Nz7YcGAAAAqLFhW/BUq9Xce++9Oeuss3LNNdcMvb948eJ873vfS5J873vfy3vf+96h9zdt2pRqtZoXXnghTU1N/+d4FgAAAMBINGyPaD3//PPZtGlTZs2alU9/+tNJkt/7vd/Ltddem9WrV2fjxo1Dj0lPkgsvvDDbtm3LrbfemsbGxtx8881Fjg8AAABQM5VqtVoteogi7dmzp+gRYFhyJhqKIXtQe3IHxZA9ThX34AEAAACglBQ8AAAAACWn4AEAAAAoOQUPAAAAQMkpeAAAAABKTsEDAAAA50tFjQAADolJREFUUHIKHgAAAICSU/AAAAAAlJyCBwAAAKDkFDwAAAAAJafgAQAAACg5BQ8AAABAySl4AAAAAEpOwQMAAABQcgoeAAAAgJJT8AAAAACUnIIHAAAAoOQUPAAAAAAl11D0ACfT97///axbty6Dg4P5wAc+kGuvvbbokQAAAABOuRGzg2dwcDD3339/PvvZz2b16tV58skns3v37qLHAgAAADjlRkzB09HRkenTp2fatGlpaGjIsmXLsnXr1qLHAgAAADjlRkzB093dncmTJw+9njx5crq7uwucCAAAAKA2RtQ9eE5Ee3t72tvbkyR33HFHWlpaCp4IhqeGhgb5gALIHtSe3EExZA9OrhFT8DQ3N+fAgQNDrw8cOJDm5ub/87m2tra0tbUNve7q6qrJfFA2LS0t8gEFkD2oPbmDYsgep8qMGTOKHqEQI+aI1pw5c/Laa6+ls7Mz/f392bx5cxYvXlz0WAAAAACnXKVarVaLHuJk2bZtW77yla9kcHAw73//+3PdddcVPRIAAADAKTdidvAkyW/91m/l7rvvzpo1a5Q78GtatWpV0SPAaUn2oPbkDoohe3ByjaiCBwAAAOB0pOABAAAAKDkFD/AL/fzT5oDakT2oPbmDYsgenFwj6ibLAAAAAKcjO3gAAAAASk7BAwAAAFByCh4AAACAklPwwGmovb099913X/bu3Vv0KHDakDsohuxB7ckdFEPBA6eRwcHBbN68Od/61rfy6quvpqOjI319fUWPBSOa3EExZA9qT+6gWPWf+9znPlf0EMCp1d/fn7q6ulQqldTX1+dDH/pQxo0bl127dmXKlCmZNGlS0SPCiCN3UAzZg9qTOxgeFDwwwj388MN57LHH0tvbm5aWlkyePDmNjY2ZMWNGtm/fnr6+vrzrXe9KY2Nj0aPCiCF3UAzZg9qTOxg+FDwwQv30pz/NF77whQwMDGTp0qXZtGlT+vr6cs4556Suri51dXVpaGjIs88+mzPPPDPTpk0burZaraZSqRQ4PZST3EExZA9qT+5g+FHwwAjzsy/Mvr6+VCqV3HjjjZkxY0b6+vrywx/+MEuXLs3g4GAqlUqmT5+eV155JceOHUtPT0+effbZzJ071xcuvENyB8WQPag9uYPhS8EDI8SxY8fywAMP5NVXX824ceMyffr0nHPOOalUKqlUKmloaMi2bdty8cUXp6GhYeiLd9SoUbn//vuzbdu2zJs3L/Pnzy96KVAacgfFkD2oPbmD4c9TtGAE6O3tzT333JOBgYEMDAzkvvvuy44dO9LY2Ji6ujdj/txzz6WlpSWjRo1KktTV1eXw4cPZsGFDFi1alHvuuSfXXHNNkcuAUpE7KIbsQe3JHZRDQ9EDAL++119/Pd3d3bntttuSJKNHj86OHTsyduzYzJs3L0myb9++vPvd706SvPTSS5k4cWKam5vzp3/6pznjjDMKmx3KSu6gGLIHtSd3UA528EAJ7du3L48++mh2796d/v7+vOtd70pLS0ueffbZJMlFF12UhoaGPP/88zl+/HiS5Pjx4zl8+HD++q//Ot/4xjfS39+fJL5w4QTJHRRD9qD25A7KyQ4eKJHBwcE89NBD2bZtW+bMmZMXX3wxZ599dj7ykY9k9uzZefnll/Pud787LS0tmTVrVl544YU0NDTk4MGD+c///M+8+OKLWb58ea6++uqilwKlIXdQDNmD2pM7KDc3WYYS6ejoyMsvv5w/+qM/ytKlSzN58uQ88cQTueiii9Lf35+f/OQnGRgYyFlnnZUpU6Zk/fr1WbZsWZqbmzN69Oh8/OMfz7nnnlv0MqBU5A6KIXtQe3IH5WYHD5TI7NmzM3bs2IwZMybJm79lGTt2bEaPHp0FCxbkwIED2bhxY6ZOnZokOfvss4ceQ+mmdvCrkTsohuxB7ckdlJuCB4apnp6ejB8//i3vNTQ0ZObMmW95ffjw4fT19aWpqSltbW2pVqv5x3/8x/zP//xPPvrRj2bSpEm1Hh1KS+6gGLIHtSd3MPIoeGAYeuSRR/L1r389n/70p7N48eJUq9VUKpUMDg6mrq5u6L/PPfdcZs6cmcbGxiRJpVLJlVdemaVLl2bChAkFrwLKRe6gGLIHtSd3MDK5Bw8MI//1X/+VtWvXplqtZt68eRk7dmxaW1tTqVRSrVZTV/fmg+9+9nrHjh1ZunRpOjo68jd/8zeZMWNGWlpaMnr06IJXAuUhd1AM2YPakzsY2ezggWGis7Mzu3btyk033ZTf/M3fzIMPPphDhw4lydBvVX784x/nH/7hH/KHf/iHmThxYp555pk89thjOfvss3PDDTdkwYIFBa8CykXuoBiyB7UndzDyKXigQD09PXnmmWeyaNGiTJ06NR//+MeH/m7u3Ll56KGH8pGPfCSVSiU7duzIt7/97Vx44YWZOHFiDh8+nAkTJuTaa6/NsmXLClwFlIvcQTFkD2pP7uD0UqlWq9Wih4DT0ebNm7Nhw4acc845mTBhQmbPnp2rrrpq6Mzza6+9ln/6p3/Ktddem5kzZ6a3tzdjxowZ2jqbZOizwImROyiG7EHtyR2cfuzggYJ0dnbmYx/7WN73vvdl165d+eY3v5lp06blwgsvTPLm2ed9+/YNPabyZ1+4P/9F6wsX3hm5g2LIHtSe3MHpR2KhIC+88MLQn9/znvfk8ssvzz//8z8PvTd9+vQ0NTVl8+bNSeKLFk4CuYNiyB7UntzB6Ud6ocYGBweTJBdffHG+9a1vDb1/ySWX5IwzzsgTTzwx9N7cuXPT19eXgYGBms8JI4ncQTFkD2pP7uD05THpcAodPHgwY8eOHXoyQfLmdtjBwcHMnj07W7Zsyf/+7/9mzpw5GRgYyMGDBzM4OJg5c+akUqlk9OjRWbJkSRoanKaEEyV3UAzZg9qTO+Dn2cEDp0BHR0f+4A/+IJ///OeTZOgLN3nrzep+53d+J9/85jdz4MCBNDY2pqurK2PGjBn6/Ny5c33hwgmSOyiG7EHtyR3wi9jBAyfR4OBgKpVKnnjiiVxwwQXZu3dvBgYG0traOvSZSqWSzs7OPPzww7n88stz7NixPP3003n00Uezf//+LF++PJMmTSpwFVAucgfFkD2oPbkDfhl1LZwEAwMDeeCBB9Lf359ly5Zl6dKlmTJlSqZMmZJ169Zl6dKlGTduXJLk+9//fr7yla9k+fLlqa+vz/XXX5/Dhw/nRz/6UZYsWVLwSqA85A6KIXtQe3IHnIhKtVqtFj0ElFm1Ws3999+f3t7eXHDBBdm0aVMWL16ctra2NDQ05M4778y0adNy4403JkmOHz+e/v7+jB8/Pslbt9ECJ0buoBiyB7Und8CJknT4NR07diyvvPJKfv/3fz+XXXZZrrnmmrz22mtDTyi44YYbsmXLlnR1dSV58zcw48ePT39/f6rVqi9c+BXIHRRD9qD25A44Ue7BA7+mUaNG5Qc/+EGOHDmSefPmZeLEiTl69Gg6Ojoya9asTJ06NW+88Ua+/e1v5wc/+EF2796dc889N3V1dW+5IR5w4uQOiiF7UHtyB5wodS6cBBdddFFeeeWVHDx4MGPGjMmsWbMyatSoHDlyJEnS29ubnTt3ZtKkSfnd3/3dgqeFkUHuoBiyB7Und8CJUPDASbBgwYJMmDAhjz/+eJKktbU1HR0d6e/vz0svvZQ33ngja9asyYoVK4odFEYQuYNiyB7UntwBJ8JTtOAkmDRpUt773vfmwQcfzPTp0zNnzpw0NDSkvr4+ra2tb3l0JXByyB0UQ/ag9uQOOBGeogUn0fbt2/PUU0/lhRdeyFVXXZWrrrqq6JFgxJM7KIbsQe3JHfDLKHjgJOvv70+lUkl9fX3Ro8BpQ+6gGLIHtSd3wNtR8AAAAACUnJssAwAAAJScggcAAACg5BQ8AAAAACWn4AEAAAAoOQUPAAAAQMkpeAAAAABKrqHoAQAA3olbbrklhw4dSn19ferq6jJz5sxcdtllaWtrS13dL//dVWdnZz75yU/m61//eurr62s0MQDAqafgAQBK57bbbsv555+f3t7e7Nq1K+vWrUtHR0duvvnmokcDACiEggcAKK2mpqYsXrw4EydOzJ/92Z/lmmuuSVdXVx566KHs27cvTU1Nef/735/rr78+SXL77bcnSW666aYkyZ//+Z9n/vz52bhxY/71X/81hw4dyty5c/OJT3wiU6ZMKWpZAADvmHvwAAClN3fu3DQ3N+dHP/pRRo8enU9+8pNZt25dVq1ale9+97v57//+7yTJX/7lXyZJ1q9fn6997WuZP39+tm7dmocffjh/8id/kvvuuy8LFizI3XffXeRyAADeMQUPADAiNDc3p6enJwsXLsysWbNSV1eX3/iN38gll1ySXbt2ve113/3ud/PhD384M2fOTH19fT784Q/nlVdeyf79+2s4PQDAr8cRLQBgROju7s748ePz4osv5sEHH8xPfvKT9Pf3p7+/P0uWLHnb6/bv359169blq1/96tB71Wo13d3djmkBAKWh4AEASq+joyPd3d1ZsGBBvvjFL+aDH/xgPvOZz6SxsTHr16/P4cOHkySVSuX/XNvS0pLrrrsul156aa3HBgA4aRzRAgBKq7e3N88880zuvvvuXHrppZk1a1aOHTuW8ePHp7GxMR0dHXniiSeGPn/GGWekUqlk3759Q+/99m//dh555JG8+uqrQz/zqaeeqvlaAAB+HZVqtVoteggAgBN1yy235NChQ6mvr0+lUsnMmTNz6aWX5sorr0xdXV22bNmSr371q+np6cl73vOeTJkyJUePHs2tt96aJPnGN76R//iP/8jAwEA++9nPZv78+dm0aVP+5V/+JV1dXWlqasp5553nkesAQKkoeAAAAABKzhEtAAAAgJJT8AAAAACUnIIHAAAAoOQUPAAAAAAlp+ABAAAAKDkFDwAAAEDJKXgAAAAASk7BAwAAAFByCh4AAACAkvt/ojyyhwYQgf0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1152x576 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    }
   ],
   "source": [
    "test_agent(test_env, visualize=True, test_episodes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kagGb2xe2cv4",
   "metadata": {
    "id": "kagGb2xe2cv4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "FraqLDCBRr9X",
   "metadata": {
    "id": "FraqLDCBRr9X"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "RL_with_cost_v4.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
